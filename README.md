# Feature tracking algorithm based on event-camera using an approach multithreading

This repository implements an improvment of the algorithm described in the 2019 IJCV paper [**EKLT: Asynchronous, Photometric Feature Tracking using Events and Frames**](http://rpg.ifi.uzh.ch/docs/IJCV19_Gehrig.pdf) by [Daniel Gehrig](https://danielgehrig18.github.io/), [Henri Rebecq](http://henri.rebecq.fr), [Guillermo Gallego](http://www.guillermogallego.es), and [Davide Scaramuzza](http://rpg.ifi.uzh.ch/people_scaramuzza.html) using a multithreading approach.


## Overview

This algoithm is based on EKLT, that works by leveraging the complementarity between events and frames for feature tracking. Using the events, it manages to track in the blind-time between two frames. First features are extracted on the frames and then tracked using only the events. The tracker then produces asynchronous feature tracks with high temporal resolution. More 
details can be found in the [paper](http://rpg.ifi.uzh.ch/docs/IJCV19_Gehrig.pdf) and in the [repository](https://github.com/uzh-rpg/rpg_eklt). Our job has been to make the algorithm more efficient, making it multithreaded, and making it more suitable for a possible real application of visual odometry.
For more details look at the [report](report.pdf) of our work, written in Italian for didactic reasons.

## Installation and running

For the installation refer to what is described in the eklt [repository](https://github.com/uzh-rpg/rpg_eklt), but with some differences. Inside folder `config`, there is the file `eklt.conf`, wich now contains a parameter that allows to specify the number of threads. In addition, the command for build the project now is `catkin build eklt_multithreading` instead of `catkin build eklt`. Finally, the command for the launch is `roslaunch eklt eklt_multithreading.launch` instead of `roslaunch eklt eklt.launch`


## Evaluation

The tests were performed on different thread numbers, and all of them were performed with Ubuntu 16.04 and ROS Kinetic.
The tracks file generated by the execution of the algorithm contains all of the information necessary to reconstruct feature tracks. The feature tracks are stored in the following format:

|feature id| timestamp          | x     | y     |
|:--------:|:------------------:|:-----:|:-----:|
|0         |1468940293.922985274|187.032|132.671|
|2         |1468940293.958816290|204.603|105.36 |
|1         |1468940293.957388878|222.378|104.176|
|0         |1468940293.964686394|223.596|19.1384|
|1         |1468940293.960546732|182.122|52.1019|
|2         |1468940293.960608244|172.227|47.1469|

The performances observed using different thread numbers are summarized in the following table.
![Performance](/images/tabella_ris.png)

The following graph shows the trend of the seconds in relation to the number of threads.
![Seconds in relation to the number of threads](/images/grafico_ris.png)



## Additional Resources on Event Cameras

* [Event-based Vision Survey](http://rpg.ifi.uzh.ch/docs/EventVisionSurvey.pdf)
* [List of Event-based Vision Resources](https://github.com/uzh-rpg/event-based_vision_resources)
* [Event Camera Dataset](http://rpg.ifi.uzh.ch/davis_data.html)
* [Event Camera Simulator](http://rpg.ifi.uzh.ch/esim)
* [RPG research page on Event Cameras](http://rpg.ifi.uzh.ch/research_dvs.html)
* [EKLT Conference paper, ECCV'18](http://rpg.ifi.uzh.ch/docs/ECCV18_Gehrig.pdf)
